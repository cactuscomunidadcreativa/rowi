// src/app/api/eco/compose/route.ts
import { NextRequest, NextResponse } from "next/server";
import OpenAI from "openai";
import { prisma } from "@/core/prisma";
import { getToken } from "next-auth/jwt";
import { isEcoLLMEnabled } from "@/domains/eco/libAI";

export const dynamic = "force-dynamic";

/* =========================================================
   üåê ECO ‚Äî Communication Engine con fallback sin IA
========================================================= */
type Channel = "email" | "whatsapp" | "sms" | "call" | "speech";
type ComposeInput = {
  goal: string;
  channel: Channel;
  memberIds?: string[];
  freeTargets?: { name: string; brainStyle?: string; description?: string }[];
  refine?: boolean;
  ask?: string;
  locale?: "es" | "en" | "pt" | "it";
};

/* =========================================================
   ‚öôÔ∏è Setup IA (si est√° permitido)
========================================================= */
const ai = process.env.OPENAI_API_KEY ? new OpenAI({ apiKey: process.env.OPENAI_API_KEY }) : null;

const PREFS: Record<string, { prefers: string; tone: string }> = {
  Strategist: { prefers: "claridad, foco y estructura", tone: "directo y preciso" },
  Scientist: { prefers: "datos y m√©todo", tone: "anal√≠tico y sobrio" },
  Guardian: { prefers: "estabilidad y confianza", tone: "cauto y formal" },
  Deliverer: { prefers: "acci√≥n r√°pida y resultados", tone: "concreto y resuelto" },
  Inventor: { prefers: "ideas y posibilidades", tone: "creativo e inspirador" },
  Energizer: { prefers: "impacto y entusiasmo", tone: "motivado y √°gil" },
  Sage: { prefers: "significado y prop√≥sito", tone: "reflexivo y profundo" },
};

/* =========================================================
   üß† POST handler ‚Äî usa IA solo si est√° habilitada
========================================================= */
export async function POST(req: NextRequest) {
  try {
    const token = await getToken({ req, secret: process.env.NEXTAUTH_SECRET });
    const email = token?.email?.toLowerCase() || "";
    const user = await prisma.user.findUnique({ where: { email } });

    const body = (await req.json()) as ComposeInput;

    const allowAI = user?.allowAI || false;
    const ecoEnabled = allowAI && isEcoLLMEnabled();

    // === Contexto base ===
    const target = body.freeTargets?.[0] || { brainStyle: "Strategist", name: "tu interlocutor" };
    const style = PREFS[target.brainStyle || "Strategist"];

    /* =========================================================
       üß© Si IA no est√° permitida ‚Üí fallback local
    ========================================================== */
    if (!ecoEnabled) {
      const base = {
        subject: `Comunicaci√≥n con ${target.name}`,
        text: `Hola ${target.name},\n\n${body.goal}.\n\nComunica con un tono ${style.tone}, priorizando ${style.prefers}.`,
        labels: {},
        tone: style.tone,
        locale: "es",
      };

      return NextResponse.json({
        ok: true,
        mode: "no-ia",
        base,
        refined: null,
        note: "‚öôÔ∏è Modo sin IA: mensaje generado localmente seg√∫n tu estilo.",
      });
    }

    /* =========================================================
       ü§ñ Si IA est√° habilitada ‚Üí usar OpenAI
    ========================================================== */
    const basePrompt = `
Eres ECO, estratega de comunicaci√≥n.
Genera un mensaje profesional y emp√°tico.

Objetivo: ${body.goal}
Canal: ${body.channel}
Receptor: ${target.name} (${target.brainStyle})
Tono preferido: ${style.tone}
Idioma: espa√±ol

Responde en formato JSON con:
{
  "subject": "Asunto",
  "text": "Cuerpo del mensaje"
}`;

    const completion = await ai!.chat.completions.create({
      model: body.refine ? "gpt-4o" : "gpt-4o-mini",
      temperature: 0.6,
      messages: [{ role: "system", content: basePrompt }],
      response_format: { type: "json_object" },
    });

    const raw = completion.choices[0].message?.content || "{}";
    const parsed = JSON.parse(raw);

    return NextResponse.json({
      ok: true,
      mode: body.refine ? "pro-llm" : "base-ia",
      base: parsed,
      refined: body.refine ? parsed : null,
    });
  } catch (e: any) {
    console.error("‚ùå /api/eco/compose error:", e);
    return NextResponse.json(
      { ok: false, error: e?.message || "Error interno en ECO" },
      { status: 500 }
    );
  }
}